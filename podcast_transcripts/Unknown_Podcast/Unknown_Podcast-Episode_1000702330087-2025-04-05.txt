Hi, I'm Toni Cowan-Brown. And I'm Benedict Evans. We finally found ourselves in the same place, at the same time, to be able to record an episode. Yes, the right time zones, no Formula One engines running behind you, no business class lounges. So the man is off to Monaco tomorrow. Well, yeah, I know. Off to give a presentation to a big company. She's spent most of my time doing- Yes, let me explain AI. And so we haven't had a podcast in a while, and I was kind of twisting and turning thinking about some of this. And I haven't written a feature about AI in a while either. And it seemed to me that one of the things I struggle with is that what I'm most interested in and best at kind of talking about or I find most ingenious to talk about is to sort of think about different products and think, well, you can pick up eBay and Amazon and Barnes and Noble on Walmart 20 years ago, or you can pick up the iPhone and Android and Blackberry and Windows Phone and Siri 60 and Mimo and MyGo and all the stuff that was happening and kind of think, well, they're trying to do this and this product is trying to do this and that product is trying to do that and it has this problem and this advantage and this strategy. And you could look at Facebook and Myspace and Instagram and TikTok, and you could kind of think about product strategies. And the product that's built on top of the underlying technology. And one of the puzzles I have looking at generative AI right now is that on the one hand, we have all of this sort of science thing. That's to say, there's more models and more models and more models, and ever more acronyms and ever more kind of cascading complexity. Getting better, getting faster. You watch Jensen Hwang give his two hour, one and a half keynote, and then there's MCP this and ultraviolet that. And it feels a bit like looking at Moore's Law, and if there were 10 Intels, the compute goes faster. I mean, obviously, there's a whole scientific question of to whether it will keep getting faster, like the scaling question, but for the time being, more models getting faster, getting cheaper, getting commoditized, but more and more and more complexity of technology on one side. On the other side, look at Y Combinator, 90% of the startups are basically doing AI as enterprise SaaS. And so we're having the classic platform shift of, here is this new technology, here are hundreds of companies that are going to try and use this to solve some problem inside big companies, to unbundle something out of Excel, Salesforce, email, Oracle, whatever, solve some point solution. So I just made some slides about this, and one of my slides is, well, here's this company that's using LLMs to automate reconfiguration of complex telco building systems. There's another one that's using LLMs to make it easier to convert legacy mainframe code into Java. These are like, is that an AI company or is that like a, not really, it's something else. It's a telco software company. So you've got all this SaaS activity happening on one side, and you've got all the science and stuff, the research labs happening on the other side. And you've got a bunch of corporate structure and financing activity going on with raising billions of dollars here and there and everywhere. And then you've got the kind of the chatbots. They're like the product as product that the rest of us are given if we're not trying to convert Cobalt into Java. Like you go to ChatGPT, you go to Anthropic and what have you. And I and a couple of other people pointed out a while ago that basically, the only UI in ChatGPT is a pulldown that says, do you want to use 0.1.0.1.mini, 0.3.0.3.flash, 0.3.0.3.flash, gem and not like what? Like this sort of soup of model description. And I feel all day looking at this stuff, and I look at that and think, well, how would I know which problem is going to be best for which of these? And the thing that kind of stopped me stepping back from this is, I've got a folder on my phone called AI, and there's eight or nine apps in it. What's the difference between them? Graphic design. Some of them have got an icon that's a line drawing, and some of them got an icon that's like a bluey-purple swoosh. Some of them have got a flat UI, and some of them have got purple sparkles. Actually, most AI has purple sparkles. It's like as a union rule, if you have AI, it's got to have purple sparkles. And from time to time, one of them can do something notably better. So like, you know, ChatGPT launches notably better in its generation thing, which is much better than the Jenny, because you can ask it to change that picture rather than kind of pulling the prompting slot machine lever and just getting something different. And that seems to be what captures a lot of the headlines these days, of just like, it's faster, it's better, it's more concise, it's easier to use. But every now and then, there's something tangible where you can say, this is different, like the OpenAI's latest model generator is different to Mid-Journey because it knows what the picture was, and you can say, add something to this, and it will add it to that picture. But as I wrote a month or two ago, like you get the new model and it's very tough to tell, actually, to tell why it's better, unless you've got some sort of text file full of weird logic puzzles that you try, and it's like, oh, I get this one right, and it didn't get that one right. Years ago, there was, I think, one of the US late night TV show guys, used to do a bit where he'd go out on the street and do a Vox Pop and interview people just after the new iPhone had come out, and he'd show them an iPhone and he'd say, this is a new iPhone, isn't it great? And they would look at it and go, wow, wow, this is much better. And of course, the jake was showing them lastly his iPhone, because no one could tell, really. And that's kind of what it feels like picking up the new model. And yes, over time, they get faster and they're twice as good now, as they were a year ago. But what I'm kind of circling around is, you've got all the science and model building on one side, which is fundamentally commoditized. And on the other side, you've got people building individual very specific pieces of vertical software that you can assess as pieces of vertical software. Will using LLMs to help you convert Cable into Java be a good company? Well, you need to ask somebody who knows a lot about Cable and Java, but there's not a broader question there. But it's very difficult to say, why will Amstropic beat ChatGPT? And if you do try and answer that question, it will be something to do with very, very arcane scientific approaches, or it will be something to do with capital raising. But it won't be the equivalent of saying, why is Amazon going to be eBay? Because they're doing something fundamentally different that's going to be better. Or they've got a different operating model that's going to allow them to do stuff that eBay can't do. It's not like looking at iPhone and Android and saying, well, they've got these fundamentally different approaches to what they're trying to do and how they're building the product. And you're going to, as a consumer, this is why you would choose that and this is why you would choose the other. And this is why Windows Phone isn't going to be able to get in developers because of X and Y. It's very hard to hold like Mistral and Mesa AI and Anthropic and Gemini, and say, aha, well, this is going to win and that's not going to win. And to think about what an actual product strategy would be within that. And I'll say there's a lot of comment and stop monologuing, but it seems to me that, like we were talking about this before, and you can talk about the corporate strategies. Like Mesa is trying to make LLMs into a generic commodity infrastructure that's sold at marginal cost because they want to differentiate on the features on top. And Amazon wants that too because they sell generic commodity infrastructure at marginal cost. That's AWS business. Whereas Microsoft and Amazon have a kind of a different strategy because they've got a bunch of, they were trying to make it a feature as well, and they don't want it to be generic. And you can kind of keep going with like, what are they trying to do as companies in building models? But what you have as the model is completely undifferentiated, except at the level, as I said, of what color is the icon. It's kind of a challenging, provocative thing to say, perhaps. But yes, I'm sure if you use all of these things every day, you would say, oh, but you know, Antelope is much better at code and ChatGVT is much better at multi-stage reasoning. Well, yes, but give this to a random person on the stream. So you want to try and compare two mortgages, which one would you use? But how would you know? Are you saying then that there's, are you looking at this and thinking, well, what's the product strategy here from all of these tools? Or are you looking at this and thinking, is there a different way that we should be thinking about what a product is in this era right now? Also, it's a puzzle. Versus the way we used to look at it. So it's a puzzle in that, I should say that OpenAI hired Kevin Weill and Anthropic hired Mike Krieger, who were both, Mike Krieger founded Instagram, Kevin Weill was head of production Instagram for a while. You do get a sense, it's like they get an email in the morning that says, we've got a new voice memo, we've got a new voice model, so you need to add a button for voice. Yeah. This is slightly unfair. These are clever people doing clever stuff, but there's a little bit of that. It's not like they're deciding what the product strategy is. But some of this is also inherent in the idea that this is like a generalized universal piece of software, that is not a dedicated product, that does a dedicated thing. It's not an image editing program. It's not photo sharing. It's not vertical video with a recommendation algorithm. They're not trying to do one specific thing and build out from that, and those other people are trying to do another specific thing and build out from that, and you might overlap. The messianic, hand-waving, imagining the future five years vision is, this is you just go and ask our GPT to do the thing for you, and so that. And you had a nice way of describing it, that you would look at, we had companies that made features, we had companies that made APIs, we had companies that made commodities, and we're somewhat stuck in this space right now, which is like we make better models. Well, this is my point about what is Meta trying to do at a corporate level, versus what Amazon is trying to do at a corporate level, versus what Apple and what... Yes. In a sense, you could put a fuzzy continuum and say that Meta and Apple and Amazon have got a lot in common, in that they all essentially think that the differentiation... Apple and Meta think that the point of this is what individual specific features do you build on top using it. Therefore, Apple talks about Apple Intelligence features, and it talks about individual features that it's built, some of which it realized it can't ship yet. But Apple's narrative is all about, here are the 10 things we're going to do with this right now. That is also how Meta thinks about it, and therefore they want the model itself to be a generic commodity, which is why they make it open source and give it to anyone to try and push the cost down because they're not going to try and differentiate on the model. They're going to differentiate on what they build on top. And that overlaps with Amazon, which is in the business of selling... AWS, which is in the business of selling generic commodity infrastructures that sell at marginal cost, so that works fine for them. Amazon, sorry, and Microsoft and Google are in a slightly different position in that they have a cloud business that wants to be selling different, that sells models, but they would rather, they were not cheap in commodities. And they also have kind of product businesses in everything that Google does, and in Office and everything else, where this enables new features. And of course, Google has an existential question, unlike most of the others, in that there's an idea that this fundamentally changes the nature of search, where I think there's still a sort of unproven, uncertain answer to that, but maybe. All of which is to say, well, they're all building models in different ways, instead of climbing the same mountain from different directions. But as a user looking at five screenshots, if I hit the brand and you put the same thing in, how would you know? And yes, you can say at one level you wouldn't really know the difference between iOS and Android, but there are pretty basic differences in how they work and what they do and what they're trying to do. And the very big difference between how eBay works and how Amazon works, or how YouTube works and how TikTok works. And it's much less clear. You mentioned also the user, which I also think is really interesting, is who's the end user of all of these new products and new different tools that will be given. We've talked about this at Lemp, but it is interesting. AWS is obviously a big sponsor of Formula One, and it was interesting digging in with them of just how much Gen.AI and AI is actually used by the teams, or AWS's AI is used by the teams in Formula One. But as a main consumer or user myself, I had no idea about this. I don't need to use their tools, their AI tools and their AI offering. But if you're a very specific user, so it just becomes interesting of who's the end user here at the end of the day for all of these things. Well, if you're selling API calls to models, then you've got an analysis of which family of models is better at your specific tasks, and also an analysis of do you want the best, fastest, most expensive model, or the slightly less good, slightly less fast, or maybe, obviously fast is a different axis, but better, the answer is better, faster, cheaper. Do you want the fast model? Do you want the best possible model? Do you want the cheap? Do you not care? Or are you willing to take 20 percent cut-in model quality for a 95 percent cut-in price? There's a very, very steep cost curve here. So there's a lot, and that gets back to my point about all the SaaS companies, hundreds and hundreds of SaaS companies, most of them using API calls to either the various third-party cloud providers that are running open-source models or to AWS or Azure or GCP or OpenAI or Anthropic. And they're sitting and making specific. And then for them, the product decision is on the one hand, it's an infrastructure decision, which piece of infrastructure do I want? And on the other hand, they're building something that lets you reconfigure Telco billing systems, so they've got Telco product decisions. If you're an engineer, then you're looking at benchmarks, maybe you're looking at benchmarks too much and trying to build a model that produces better results in the abstract. But you've got this kind of fuzzy middle ground in the middle of, do you use AI? And I don't really want to spend, go down another rabbit hole of like, what would you do with this? How do we think about use cases? Because we've done that far too much. The point is, whatever your use case is for ChapGPT, there's not any particularly obvious reason why you'd be using ChapGPT versus Anthropic versus MetaAI versus Gemini. And certainly not why you'll stick with it over the next six months or a year. With two exceptions. And I think one exception is kind of branding and habit and the default. And that's the one that you're used to using. And the other is whether we get to a point that these models know more about you, that you've used them sufficiently for long enough, that you can ask them stuff that requires knowledge of the other questions you've asked over the last six months or a year. Which is not quite, certainly is stickiness. It's not quite a network effect. It might be a network effect. It could turn into a network effect of what other people like me tend to do. But the stickiness of it gets easier and easier to use these models because they learn from you and they learn how you think and what you need. Or they've got some history. They said, two weeks ago, I asked about this, or looking at the kind of stuff I've asked about, what would I like about this, and so on. So there's some context and some history, which is also the stuff Apple talks about. But that's a separate thing to product strategy of its own. Which is interesting because it comes back to the question I think you and I landed on when we were chatting about this a couple of weeks ago. And I remember you saying the big question or goal here is, how do we make these tools become a central part of your life? Like how does this become the thing that you wake up in the morning and you have to use? Or it becomes part of whatever process you use to do a job or your day-to-day work. But then we both looked at each other and came down to, okay, so this is marketing? Well, this is kind of my question, is OpenAI a technology company or a branding company? So true. And this is always the dumb criticism of Apple from people who don't understand the product differentiation. There's a bunch of people who look at Apple and say, well, it doesn't do the stuff I want to do. Therefore, it's a crap product. And then people would only buy it if they've kind of been tripped by the marketing. And people who don't understand, like, no, it's a different proposition. OpenAI, why would I use OpenAI over Answapic, over Mistral, over DeepSeek, over TatsyPT, over MetaAI? Is it because one of them produces notably clearer, more obviously better results? Is it because they've got a better product? And that also might change from one week to another, as you map out. Yeah, exactly. Well, this is the thing. So you go to LM Arena, and right now Gemini 2.5 is the best model by like, what's the score? The next bet, the Gemini score is like 1440, and the next best score is like, GROK is 1405, and then TatsyPT something, something is whichever model they're versioning on now is like 1404. No consumers going looking at those things. So you've got this kind of, I mean, one of the things I was thinking about, and this is probably a bit harsh, is there's a slight echo here of metaverse. Okay, in what way? Well, in the sense that- Because you were very critical of the metaverse. Well, what I was critical of was the word. Okay, all in public. Because I felt like we could sit and talk about AR and VR. I can talk about games. I can talk about social networks. I can talk about crypto and NFTs. And it's all interesting conversations. You know, I don't have very much time for NFTs, but like this, you know, there are specific tangible technologies and use cases and ideas of what you might do. But if somebody said metaverse, you had no idea what they meant. Were they talking about? Did they mean you'll be able to transfer assets seamlessly between games using NFTs? Which didn't make any sense to me, but maybe. Do they mean everyone will be wearing a pair of AR glasses? Did they mean something else? And you didn't know? Visual representation of what that metaverse would be. You had no idea. You couldn't actually know what somebody meant when they said metaverse, because although yes, theoretically, like Bruce Dulling or whoever used it in a book 30 years ago, like that wasn't, no, you didn't know what anyone meant when they said it. And we're sort of a point now where people will say, what do you think about AI? And I think- Which bit? What part? What are you asking me? I mean, I had a conversation a couple of days ago with a political journalist. He said, well, shouldn't we regulate AIs to make sure it follows our values? And I gave my example of configuring telco billing systems. Do you think Brussels needs to pass a law to make sure that the company that's helping a big telco reconfigure its billing systems to incorporate a different pricing plan needs to reflect our democratic values? What are you talking about? What does that mean? And if you- What you actually mean is people building systems that will decide who gets parole. Fine, then let's talk about that. Fun fact, by the way, I was sent a newsletter of that exchange that you had with the journalist with the title, I think, is AI Act Critics Line Up. Benedict Evans. Tech Guru slams the EU's- I'll send it to you. I really haven't seen that. I'm looking at it now, but Tech Guru slams the EU's AI rules. Someone sent it to me, is this your co-host? I was like, yes. Oh, it's just your hand being pretty protective of their regulation. It's my point about what do you mean by when you say AI? What's the right level of abstraction here? Should you be talking about regulating AI, or should you be talking about we don't want people using face recognition to decide who can get into a conference hall? Which is not an AI question, that's something else. And there's this sort of thing here of like, you have this tension between the general purpose model, around the general, how do you differentiate? This is really, I suppose, what I'm groping towards is, what would it even mean to have different product strategies for something where the whole concept is it does everything? How do you have different kinds of everything? Which sounds like all of these companies and all of these products are going to have to, we were joking about this, but it is going to be a massive marketing exercise of who's your audience, who's your end user, how do we put this product in the center of their day-to-day lives? How does this make their job, their life 10x better? How does it become sticky? But part of it is the product, but a big part of it also is the marketing aspects of this. Well, there's a marketing, two slightly different things here. There's a marketing question of how we did that you go, and I've had talks with people at several of these companies recently, of how is it that we would go and tell people why this is great and why they should be using it? But I'm not thinking as a slightly set for point is, that's a different question to why should I use Chatsy EPT versus Anthropic when the whole idea is that, if the model can do everything, then how could you differentiate it? Because they would both do everything. I mean, the only thing I can think of is like, and it's very bizarre, but it's like fast food chains, like how do you differentiate a McDonald's from a Burger King from it? Well, I would say like branding and brand advertising. It's advertising where you're not actually trying to communicate something different about the product. I was going to say, it's the emotional selling aspect of it. Apple did it always very well of just like, you want to become an Apple user, and you just, you know, Adji has... Yeah, he said that Apple actually had, there was some tangible way in which it was different. It was reflected in his brand. And, you know, I worked at a branded company a long time ago. Do you think everyone's going to argue, but yes, our product is different in a certain way? Or are you saying it's actually almost impossible with these tools right now to say that your product is different? I would say there's an end point here, which is to look at something like beer advertising. We've got some fast food to be in. Where there really isn't any, you know, there's a difference in taste, but there's really no difference to bring. Okay, it's personal choices. Or like some kinds of car advertising, you're advertising an urban runabout. They will basically, there's no meaningful difference between them. They're all very reliable. They've all got the same doors and the same luggage space. It's the emotional attachment. It's purely, you know, you're showing the ad or like, you know, soap powder. High-end jewelry, watches, same thing, like it's a personal, it's something that, yeah. So, the challenge, the puzzle is, the models are all getting better, but they're all getting better in exactly the same way, at exactly the same pace. And which one is, strictly speaking, at the top of the leaderboards, kind of partly depends which leaderboard. So, are you looking at image generation versus coding, versus storytelling or something? But in generality, they are A, commodities and B, the dream is that the model can do everything. So, how would you differentiate something that's a commodity when the entire thesis is, it does everything? Like, our one does everything differently from that one that does everything. Well, what would that mean? And so, that gets you to a branding and marketing story. Or, of course, it gets you to who raised most money and can carry on building this stuff story. And here's a question for you. Do you think that all of these companies are doing a good job at marketing themselves, or do you think they're focusing way too much on the products? And I know that's a- Well, so, you know, what is it that Sam Altman spends his day doing, time doing? You know, I sometimes get the sense he spends most of his time lobbying and talking and promoting OpenAI. What is he doing? Quite a lot of what he's doing is talking to policy makers and opinion formers and trying to position your sense of what this company is. What is it that Dario Amodi, if I'm pronouncing that right, you know, his public persona, the message that he goes out and tries to tell, what is the message that Metta and Google go out and try and tell, probably rather, they have a less clear public story about this at the moment. Obviously, Metta has a strong open-source story to engineers. It doesn't necessarily have a strong quote-unquote AI story to anyone else yet. Apple has obviously put Apple Intelligence on billboards everywhere and had this coherent set of individual specific features, and then of course failed to launch the most important one. But you've got this, as I said, and now I'm kind of repeating myself, very unclear what the end game is, where the value capture would be, what the market structure will look like. If we get to a market structure in which you have models that can do anything and there's half a dozen of them, how would they compete with each other? How would one of them capture more of the market from the others, other than price and brand? Which is not like a particularly encouraging story to if you're investing in these things. I mean, I have a- You remember I wrote about the Jevons Paradox in 20- I think in 2023, maybe, certainly 2024. Then earlier this year Satya Nadella looked at deep-seek and says, yes, but the Jevons Paradox means if something gets cheaper, people will use more of it, not less of it. And I looked at that and I thought, tell that to a Telco investor or an airline investor. So I made a chart which is Telco mobile data since 2010, which according to Ericsson has gone up roughly 100,000x, and Telco stocks since 2010. Not the same trajectory. And I'm not giving very much away to say that they haven't gone up by 100,000. They've been basically flat since 2010. The correlation isn't quite there. Just because if you make something much cheaper, people will probably use much more of it up to a point. Although interestingly, there's a debate now as to whether mobile data traffic is actually slowing down. But that doesn't mean you'll be able to charge much more money for it. And it's that same analogy as probably because you built it and people are going to come. You still have to get it in front of people's faces. Well, you built it and people come, but then that doesn't mean you make any money from it. I mean, this is the story of telcos of the last 20 years. Yeah, but I don't know if this is the point. The telcos, this is the story of telcos of the last 20 years is, 5G networks are these incredibly amazing things, and they've changed our lives, and we all use them all the time every day. And guess how much money telcos make from it, like fuck all. Which is another question, like how are they going to make money, which is another. Yeah, but I'm going to get on a plane tomorrow and fly from London, and they end up in Monaco, and then back again in like three days. So not very much money in the great scheme of things. It's amazing. Yeah. Do the airlines make any money out of this? Not really. It's modern infrastructure. And what do you do? You differentiate on the business classes. Yeah. I liked how you described it the other day, and I think this is a nice way of wrapping it up, that it all sounds like this is a great marketing company with a lab attached to it. It's an unfair description of open AI. I know. I was going to say it's a bit of a pessimistic one, but... There they are, with 10,000 engineers doing incredibly cool, sexy, exciting stuff, but where's the money coming from? And you look at it and go, oh, it's a nice marketing company. Yeah, it's a marketing company with a lab attached. I like it. As I said, it's like a provocative and cynical and unfair way to describe it, but it's also sort of a useful question to ask. Where's the value capture if these things are all basically commodities doing basically the same thing? And there's no differentiator, exactly. So you've got to look at it a different way. You've got to look at it for a different angle or in a different way. I like that. This was a perfect way to end. Anything else to add to that? I'll send you a selfie from Monaco. Is that where the race happens? Thank you. Yes, that is where they send me a selfie from the hairpin. Where there's very fast cars going very slowly. Very loudly. I'm not complaining. I don't think they want to try to rebuild the track. Well, in Formula One, it's really hard to overtake. In Formula E, there's lots of overtaking, obviously, because it's electric cars and the cars are smaller. But that's the joke is they've been racing on more or less the same track for 100 years. But Monaco is Monaco. There is no more space to build. This is the track that we have. But the cars have gotten a lot heavier, a lot wider, and a lot longer. So you look at these cars and you look at the roads and you go, there's no way in hell that one tonne, more or less one tonne cars, there are these massive, massive, massive pieces of machinery go down and overtake each other. You can't fit two cars side by side. So they just don't overtake, they just go round and round. So it's just that beautiful, what was it, that British comedian who said, it's a televised traffic. That's what, and Monaco is truly where we sit and we pay a lot of money to watch televised traffic. You could do the same at your Tesco garage or your parking lot. It's very loud, though. But no, it's very loud, although they want to bring, some people are wanting to bring back the V10 engines, because the engines that we have today are definitely not as loud as they used to be. But I don't know, I think there's still something quite beautiful that we've been racing there for 100 years. And here we still are. And these cars make no sense going down those streets. Well, I will go and inspect and discover the answer. Go and inspect, yeah, and go and see how the asphalt is doing. They're probably laying down more new asphalt. They have to do that. Well, next time, we'll have to do a podcast about Formula One. Content creation in Formula One on TikTok. In Formula One, some kind of product differentiation, I'm sure. Speak to you soon. Enjoy, Monaco. Bye.