# File Analyzer

## Notes
### Design
* Stateless application allows it to be scaled horizontally when deployed in a K8S like environment
* Application support async file analysis submissions, as required by the business logic
* Java `Executor` thread pool is leverage to achieve async behavior. Thread pool size and queue-depth 
is configurable, and can be tuned to achieve maximum concurrency for a particular environment. Benchmarking the 
application will reveal ideal pool configuration
* Depending on the configured thread pool parameters, the API to submit a job will fail in case the queue is full. The 
error is returned back to the user 
* Three HSETs store the application information in REDIS
  * _TASK_ Stores the task information. The key is a UUID generated by the business logic
  * _FILE_ID_REF_ Stores the File Id reference information
  * _FILE_CREATE_ Stores the File Id and when it was _last_ analyzed by a user-submitted task
* Task states
  * _PENDING_ Task created and submitted to the Executor but not yet running
  * _RUNNING_ Task being executed and analysis in progress
  * _ERROR_ Task analysis complete with error
  * _DONE_ Task analysis completed successfully
* The Service and DB layers are modeled over an interface to enable mocking for testing
* The `ResourceService` interface allows a definition of S3 Resource implementation. The current implementation is for
File resource only

## API
* Application endpoints are available at port `8080`.
* OpenAPI documentation endpoint is exposed at `/api-docs`
    ```bash
    http://localhost:8080/api-docs/
    ```
  The YAML version can be downloaded by accessing the following URL
    ```bash
    localhost:8080/api-docs.yaml
    ```

### Examples

#### Fetch API details in OpenAPI format
Fetch from console and format the JSON response using `jq`

```bash
$ curl localhost:8080/api-docs | jq
```

Alternatively, open the URL localhost:8080/api-docs in the browser

#### Submit a job
```bash
$ curl --location --request POST 'localhost:8080/analyze/24c4ace8-dbb3-4692-980f-a4c44425d2e7'
```

#### Analyze status of a submitted job
```bash
$ curl --location --request GET 'localhost:8080/analyze/f9368d7e-5f4a-42c7-9305-2dc642a5e271'
```

#### Search file references

##### with date filter
```
$ curl --location --request GET 'localhost:8080/search?from=2010-10-10&fileId=24c4ace8-dbb3-4692-980f-a4c44425d2e7'
```

##### without date filter
```
$ curl --location --request GET 'localhost:8080/search?fileId=24c4ace8-dbb3-4692-980f-a4c44425d2e7'
```


## Build and Run

The following instructions will allow the File Analyzer application and REDIS
to run in containers. Both the application and REDIS ports are exposed to the
host so we can interact with both. The application is available on port `8080`
on the host. 

_Note_: `application.properties` sets the example input files location as
`/home/app/input` so that's why the `docker-compose.yml` is defined in a way to
make these file available under that location in the container

### Build the application
```
$ mvn clean package
```

### Create a Docker image for the application
```
$ docker build --tag=file-analyzer:latest .
```

### Run the application
```
$ docker-compose up
```

## Future Work
* Add unit testing of API and Service layers. Legless testing can be achieved by mocking the DB layer
* Export stats via the micrometer API
* Normalize exception handling by moving all exception handling and associated REST error responses into the Controller 
advice class
* If REDIS is not available at startup, the application makes no attempt to retry connect. This needs to be fixed
* Transactions on the FILE_ID_REF hash set might have to be remodeled because Spring `@Transactional` support might not 
be working for REDIS, to provide true transaction isolation for updates to the `FILE_ID_REF` `HSET`. If this is a problem 
we can remodel this information as a `SET` and do explicit `WATCH` and `EXEC` operations under an explicit transaction under 
the `RedisTemplate` that we create
* REST APIs need to be versioned
